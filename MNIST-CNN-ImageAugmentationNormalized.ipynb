{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = trainDf['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainDf.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Softmax, Reshape, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_learning_rate(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Reshape((28,28,1), input_shape=(784,)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(28,28,1), activation='relu', padding='Same'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='Same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='Same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='Same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(784, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(784, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_scheduler = LearningRateScheduler(get_learning_rate)\n",
    "reduce_lr_callback = ReduceLROnPlateau(factor=0.5, min_lr=0.00001, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingImageGen = ImageDataGenerator(rotation_range=30, width_shift_range=0.2, shear_range=0.2, zoom_range=0.2, height_shift_range=0.2, vertical_flip=False, horizontal_flip=False)\n",
    "validImageGen = ImageDataGenerator(rotation_range=30, width_shift_range=0.2, shear_range=0.2, zoom_range=0.2, height_shift_range=0.2, vertical_flip=False, horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingImageGen.fit(X)\n",
    "validImageGen.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingGenerator = trainingImageGen.flow(X, to_categorical(labels),batch_size=32)\n",
    "validImageGenerator = validImageGen.flow(X, to_categorical(labels),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit_generator in module keras.engine.training:\n",
      "\n",
      "fit_generator(generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0) method of keras.engine.sequential.Sequential instance\n",
      "    Trains the model on data generated batch-by-batch by a Python generator\n",
      "    (or an instance of `Sequence`).\n",
      "    \n",
      "    The generator is run in parallel to the model, for efficiency.\n",
      "    For instance, this allows you to do real-time data augmentation\n",
      "    on images on CPU in parallel to training your model on GPU.\n",
      "    \n",
      "    The use of `keras.utils.Sequence` guarantees the ordering\n",
      "    and guarantees the single use of every input per epoch when\n",
      "    using `use_multiprocessing=True`.\n",
      "    \n",
      "    # Arguments\n",
      "        generator: A generator or an instance of `Sequence`\n",
      "            (`keras.utils.Sequence`) object in order to avoid\n",
      "            duplicate data when using multiprocessing.\n",
      "            The output of the generator must be either\n",
      "            - a tuple `(inputs, targets)`\n",
      "            - a tuple `(inputs, targets, sample_weights)`.\n",
      "            This tuple (a single output of the generator) makes a single\n",
      "            batch. Therefore, all arrays in this tuple must have the same\n",
      "            length (equal to the size of this batch). Different batches may\n",
      "            have different sizes. For example, the last batch of the epoch\n",
      "            is commonly smaller than the others, if the size of the dataset\n",
      "            is not divisible by the batch size.\n",
      "            The generator is expected to loop over its data\n",
      "            indefinitely. An epoch finishes when `steps_per_epoch`\n",
      "            batches have been seen by the model.\n",
      "        steps_per_epoch: Integer.\n",
      "            Total number of steps (batches of samples)\n",
      "            to yield from `generator` before declaring one epoch\n",
      "            finished and starting the next epoch. It should typically\n",
      "            be equal to the number of samples of your dataset\n",
      "            divided by the batch size.\n",
      "            Optional for `Sequence`: if unspecified, will use\n",
      "            the `len(generator)` as a number of steps.\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire data provided,\n",
      "            as defined by `steps_per_epoch`.\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See [callbacks](/callbacks).\n",
      "        validation_data: This can be either\n",
      "            - a generator or a `Sequence` object for the validation data\n",
      "            - tuple `(x_val, y_val)`\n",
      "            - tuple `(x_val, y_val, val_sample_weights)`\n",
      "            on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data.\n",
      "        validation_steps: Only relevant if `validation_data`\n",
      "            is a generator. Total number of steps (batches of samples)\n",
      "            to yield from `validation_data` generator before stopping\n",
      "            at the end of every epoch. It should typically\n",
      "            be equal to the number of samples of your\n",
      "            validation dataset divided by the batch size.\n",
      "            Optional for `Sequence`: if unspecified, will use\n",
      "            the `len(validation_data)` as a number of steps.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only). This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples\n",
      "            from an under-represented class.\n",
      "        max_queue_size: Integer. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Maximum number of processes to spin up\n",
      "            when using process-based threading.\n",
      "            If unspecified, `workers` will default to 1. If 0, will\n",
      "            execute the generator on the main thread.\n",
      "        use_multiprocessing: Boolean.\n",
      "            If `True`, use process-based threading.\n",
      "            If unspecified, `use_multiprocessing` will default to `False`.\n",
      "            Note that because this implementation\n",
      "            relies on multiprocessing,\n",
      "            you should not pass non-picklable arguments to the generator\n",
      "            as they can't be passed easily to children processes.\n",
      "        shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      "            the beginning of each epoch. Only used with instances\n",
      "            of `Sequence` (`keras.utils.Sequence`).\n",
      "            Has no effect when `steps_per_epoch` is not `None`.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "    \n",
      "    # Returns\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "    \n",
      "    # Raises\n",
      "        ValueError: In case the generator yields data in an invalid format.\n",
      "    \n",
      "    # Example\n",
      "    \n",
      "    ```python\n",
      "    def generate_arrays_from_file(path):\n",
      "        while True:\n",
      "            with open(path) as f:\n",
      "                for line in f:\n",
      "                    # create numpy arrays of input data\n",
      "                    # and labels, from each line in the file\n",
      "                    x1, x2, y = process_line(line)\n",
      "                    yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      "    \n",
      "    model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      "                        steps_per_epoch=10000, epochs=10)\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.fit_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1312/1312 [==============================] - 117s 89ms/step - loss: 0.3855 - acc: 0.8779 - val_loss: 0.1625 - val_acc: 0.9517\n",
      "Epoch 2/30\n",
      "1312/1312 [==============================] - 116s 89ms/step - loss: 0.1305 - acc: 0.9634 - val_loss: 0.1052 - val_acc: 0.9699\n",
      "Epoch 3/30\n",
      "1312/1312 [==============================] - 117s 89ms/step - loss: 0.1050 - acc: 0.9699 - val_loss: 0.0842 - val_acc: 0.9771\n",
      "Epoch 4/30\n",
      "1312/1312 [==============================] - 113s 86ms/step - loss: 0.0965 - acc: 0.9737 - val_loss: 0.0886 - val_acc: 0.9741\n",
      "Epoch 5/30\n",
      "1312/1312 [==============================] - 113s 86ms/step - loss: 0.0861 - acc: 0.9766 - val_loss: 0.0813 - val_acc: 0.9757\n",
      "Epoch 6/30\n",
      "1312/1312 [==============================] - 113s 86ms/step - loss: 0.0819 - acc: 0.9781 - val_loss: 0.0981 - val_acc: 0.9705\n",
      "Epoch 7/30\n",
      "1312/1312 [==============================] - 113s 86ms/step - loss: 0.0773 - acc: 0.9791 - val_loss: 0.1235 - val_acc: 0.9657\n",
      "Epoch 8/30\n",
      "1312/1312 [==============================] - 112s 86ms/step - loss: 0.0765 - acc: 0.9800 - val_loss: 0.0851 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/30\n",
      "1312/1312 [==============================] - 113s 86ms/step - loss: 0.0529 - acc: 0.9857 - val_loss: 0.0366 - val_acc: 0.9898\n",
      "Epoch 10/30\n",
      "1312/1312 [==============================] - 117s 89ms/step - loss: 0.0444 - acc: 0.9872 - val_loss: 0.0354 - val_acc: 0.9896\n",
      "Epoch 11/30\n",
      "1312/1312 [==============================] - 121s 92ms/step - loss: 0.0458 - acc: 0.9874 - val_loss: 0.0374 - val_acc: 0.9897\n",
      "Epoch 12/30\n",
      "1312/1312 [==============================] - 117s 89ms/step - loss: 0.0433 - acc: 0.9877 - val_loss: 0.0356 - val_acc: 0.9902\n",
      "Epoch 13/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0449 - acc: 0.9876 - val_loss: 0.0310 - val_acc: 0.9910\n",
      "Epoch 14/30\n",
      "1312/1312 [==============================] - 119s 90ms/step - loss: 0.0414 - acc: 0.9889 - val_loss: 0.0410 - val_acc: 0.9891\n",
      "Epoch 15/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0397 - acc: 0.9892 - val_loss: 0.0374 - val_acc: 0.9890\n",
      "Epoch 16/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0382 - acc: 0.9889 - val_loss: 0.0316 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0314 - acc: 0.9913 - val_loss: 0.0300 - val_acc: 0.9913\n",
      "Epoch 18/30\n",
      "1312/1312 [==============================] - 119s 90ms/step - loss: 0.0280 - acc: 0.9919 - val_loss: 0.0258 - val_acc: 0.9925\n",
      "Epoch 19/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0258 - acc: 0.9926 - val_loss: 0.0250 - val_acc: 0.9925\n",
      "Epoch 20/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0275 - acc: 0.9920 - val_loss: 0.0254 - val_acc: 0.9928\n",
      "Epoch 21/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0265 - acc: 0.9925 - val_loss: 0.0218 - val_acc: 0.9935\n",
      "Epoch 22/30\n",
      "1312/1312 [==============================] - 120s 92ms/step - loss: 0.0244 - acc: 0.9925 - val_loss: 0.0227 - val_acc: 0.9930\n",
      "Epoch 23/30\n",
      "1312/1312 [==============================] - 119s 90ms/step - loss: 0.0273 - acc: 0.9922 - val_loss: 0.0208 - val_acc: 0.9940\n",
      "Epoch 24/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0259 - acc: 0.9928 - val_loss: 0.0258 - val_acc: 0.9928\n",
      "Epoch 25/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0246 - acc: 0.9928 - val_loss: 0.0211 - val_acc: 0.9937\n",
      "Epoch 26/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0229 - acc: 0.9932 - val_loss: 0.0219 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 27/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0212 - acc: 0.9937 - val_loss: 0.0188 - val_acc: 0.9949\n",
      "Epoch 28/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0202 - acc: 0.9940 - val_loss: 0.0160 - val_acc: 0.9949\n",
      "Epoch 29/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0201 - acc: 0.9943 - val_loss: 0.0177 - val_acc: 0.9946\n",
      "Epoch 30/30\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0194 - acc: 0.9948 - val_loss: 0.0166 - val_acc: 0.9951\n"
     ]
    }
   ],
   "source": [
    "#model.fit(xTrain, to_categorical(yTrain), epochs=10, batch_size=256)\n",
    "history = model.fit_generator(trainingGenerator, steps_per_epoch=X.shape[0]//32, epochs=30, callbacks=[reduce_lr_callback], validation_data=validImageGenerator, validation_steps=X.shape[0]//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1312/1312 [==============================] - 132s 100ms/step - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0174 - val_acc: 0.9948\n",
      "Epoch 2/6\n",
      "1312/1312 [==============================] - 124s 94ms/step - loss: 0.0180 - acc: 0.9945 - val_loss: 0.0164 - val_acc: 0.9951\n",
      "Epoch 3/6\n",
      "1312/1312 [==============================] - 116s 88ms/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.0154 - val_acc: 0.9949\n",
      "Epoch 4/6\n",
      "1312/1312 [==============================] - 114s 87ms/step - loss: 0.0170 - acc: 0.9953 - val_loss: 0.0165 - val_acc: 0.9951\n",
      "Epoch 5/6\n",
      "1312/1312 [==============================] - 117s 89ms/step - loss: 0.0193 - acc: 0.9950 - val_loss: 0.0148 - val_acc: 0.9955\n",
      "Epoch 6/6\n",
      "1312/1312 [==============================] - 116s 89ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0152 - val_acc: 0.9954\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(trainingGenerator, steps_per_epoch=X.shape[0]//32, epochs=6, callbacks=[reduce_lr_callback], validation_data=validImageGenerator, validation_steps=X.shape[0]//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0169 - acc: 0.9951 - val_loss: 0.0152 - val_acc: 0.9953\n",
      "Epoch 2/10\n",
      "1312/1312 [==============================] - 116s 88ms/step - loss: 0.0159 - acc: 0.9950 - val_loss: 0.0160 - val_acc: 0.9951\n",
      "Epoch 3/10\n",
      "1312/1312 [==============================] - 115s 88ms/step - loss: 0.0171 - acc: 0.9952 - val_loss: 0.0143 - val_acc: 0.9956\n",
      "Epoch 4/10\n",
      "1312/1312 [==============================] - 117s 89ms/step - loss: 0.0176 - acc: 0.9946 - val_loss: 0.0146 - val_acc: 0.9955\n",
      "Epoch 5/10\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0156 - acc: 0.9954 - val_loss: 0.0148 - val_acc: 0.9955\n",
      "Epoch 6/10\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0169 - acc: 0.9951 - val_loss: 0.0140 - val_acc: 0.9953\n",
      "Epoch 7/10\n",
      "1312/1312 [==============================] - 116s 89ms/step - loss: 0.0156 - acc: 0.9956 - val_loss: 0.0137 - val_acc: 0.9957\n",
      "Epoch 8/10\n",
      "1312/1312 [==============================] - 117s 89ms/step - loss: 0.0168 - acc: 0.9952 - val_loss: 0.0144 - val_acc: 0.9954\n",
      "Epoch 9/10\n",
      "1312/1312 [==============================] - 114s 87ms/step - loss: 0.0166 - acc: 0.9951 - val_loss: 0.0157 - val_acc: 0.9959\n",
      "Epoch 10/10\n",
      "1312/1312 [==============================] - 115s 88ms/step - loss: 0.0167 - acc: 0.9952 - val_loss: 0.0143 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(trainingGenerator, steps_per_epoch=X.shape[0]//32, epochs=10, callbacks=[reduce_lr_callback], validation_data=validImageGenerator, validation_steps=X.shape[0]//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1312/1312 [==============================] - 116s 88ms/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.0114 - val_acc: 0.9963\n",
      "Epoch 2/10\n",
      "1312/1312 [==============================] - 116s 88ms/step - loss: 0.0146 - acc: 0.9960 - val_loss: 0.0126 - val_acc: 0.9963\n",
      "Epoch 3/10\n",
      "1312/1312 [==============================] - 114s 87ms/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0125 - val_acc: 0.9962\n",
      "Epoch 4/10\n",
      "1312/1312 [==============================] - 115s 88ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0124 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 5/10\n",
      "1312/1312 [==============================] - 114s 87ms/step - loss: 0.0124 - acc: 0.9966 - val_loss: 0.0117 - val_acc: 0.9966\n",
      "Epoch 6/10\n",
      "1312/1312 [==============================] - 113s 86ms/step - loss: 0.0137 - acc: 0.9958 - val_loss: 0.0105 - val_acc: 0.9966\n",
      "Epoch 7/10\n",
      "1312/1312 [==============================] - 114s 87ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0104 - val_acc: 0.9968\n",
      "Epoch 8/10\n",
      "1312/1312 [==============================] - 114s 87ms/step - loss: 0.0122 - acc: 0.9968 - val_loss: 0.0111 - val_acc: 0.9969\n",
      "Epoch 9/10\n",
      "1312/1312 [==============================] - 115s 88ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0108 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 10/10\n",
      "1312/1312 [==============================] - 114s 87ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0105 - val_acc: 0.9971\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(trainingGenerator, steps_per_epoch=X.shape[0]//32, epochs=10, callbacks=[reduce_lr_callback], validation_data=validImageGenerator, validation_steps=X.shape[0]//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1312/1312 [==============================] - 118s 90ms/step - loss: 0.0129 - acc: 0.9963 - val_loss: 0.0112 - val_acc: 0.9965\n",
      "Epoch 2/10\n",
      "1312/1312 [==============================] - 119s 91ms/step - loss: 0.0114 - acc: 0.9968 - val_loss: 0.0107 - val_acc: 0.9969\n",
      "Epoch 3/10\n",
      "1312/1312 [==============================] - 122s 93ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0108 - val_acc: 0.9966\n",
      "Epoch 4/10\n",
      "1312/1312 [==============================] - 123s 94ms/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.0103 - val_acc: 0.9969\n",
      "Epoch 5/10\n",
      "1312/1312 [==============================] - 124s 95ms/step - loss: 0.0116 - acc: 0.9968 - val_loss: 0.0120 - val_acc: 0.9962\n",
      "Epoch 6/10\n",
      "1312/1312 [==============================] - 121s 92ms/step - loss: 0.0108 - acc: 0.9968 - val_loss: 0.0099 - val_acc: 0.9967\n",
      "Epoch 7/10\n",
      "1312/1312 [==============================] - 121s 92ms/step - loss: 0.0125 - acc: 0.9964 - val_loss: 0.0109 - val_acc: 0.9968\n",
      "Epoch 8/10\n",
      "1312/1312 [==============================] - 122s 93ms/step - loss: 0.0103 - acc: 0.9967 - val_loss: 0.0099 - val_acc: 0.9972\n",
      "Epoch 9/10\n",
      "1312/1312 [==============================] - 121s 92ms/step - loss: 0.0115 - acc: 0.9968 - val_loss: 0.0100 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 10/10\n",
      "1312/1312 [==============================] - 120s 92ms/step - loss: 0.0111 - acc: 0.9968 - val_loss: 0.0117 - val_acc: 0.9966\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(trainingGenerator, steps_per_epoch=X.shape[0]//32, epochs=10, callbacks=[reduce_lr_callback], validation_data=validImageGenerator, validation_steps=X.shape[0]//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testDf.values\n",
    "#normalizing\n",
    "X_test = X_test/255\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_resultCNNImageAugmentationNormalized.csv', 'w') as fil:\n",
    "    print('ImageId,Label', file=fil)\n",
    "    for i in range(Y.shape[0]):\n",
    "        print(i+1, Y[i], sep=',', file=fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
